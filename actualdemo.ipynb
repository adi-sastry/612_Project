{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63d497c",
   "metadata": {},
   "source": [
    "DEMO 8/19:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8415f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel interpreter: c:\\Users\\Rohan\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\n",
      "Python version   : 3.10.0\n",
      "Requirement already satisfied: pip in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (25.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (80.9.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.45.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: statsmodels in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.14.5)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (2.2.6)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (1.15.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (2.3.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\rohan\\appdata\\roaming\\python\\python310\\site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rohan\\appdata\\roaming\\python\\python310\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohan\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: torch==2.6.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0+cu126)\n",
      "Requirement already satisfied: torchvision==0.21.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.21.0+cu126)\n",
      "Requirement already satisfied: filelock in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.6.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\rohan\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.6.0) (4.14.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.6.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.6.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.6.0) (2025.7.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.6.0) (1.13.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision==0.21.0) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision==0.21.0) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch==2.6.0) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pytorch-lightning==2.5.3 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.3)\n",
      "Requirement already satisfied: pytorch-forecasting==1.4.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: neuralforecast==3.0.2 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: optuna>=3.5 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: pandas>=2.2 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scikit-learn>=1.4 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.8 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: seaborn>=0.13 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: torch>=2.1.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==2.5.3) (2.6.0+cu126)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==2.5.3) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>5.4 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==2.5.3) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.5.3) (2025.7.0)\n",
      "Requirement already satisfied: torchmetrics>0.7.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==2.5.3) (1.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rohan\\appdata\\roaming\\python\\python310\\site-packages (from pytorch-lightning==2.5.3) (25.0)\n",
      "Requirement already satisfied: typing-extensions>4.5.0 in c:\\users\\rohan\\appdata\\roaming\\python\\python310\\site-packages (from pytorch-lightning==2.5.3) (4.14.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-lightning==2.5.3) (0.15.2)\n",
      "Requirement already satisfied: lightning<3.0.0,>=2.0.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-forecasting==1.4.0) (2.5.3)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-forecasting==1.4.0) (1.15.3)\n",
      "Requirement already satisfied: coreforecast>=0.0.6 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from neuralforecast==3.0.2) (0.0.16)\n",
      "Requirement already satisfied: ray>=2.2.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray[tune]>=2.2.0->neuralforecast==3.0.2) (2.48.0)\n",
      "Requirement already satisfied: utilsforecast>=0.2.3 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from neuralforecast==3.0.2) (0.2.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rohan\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=2.2) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=1.4) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=1.4) (3.6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.5.3) (3.12.15)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch-lightning==2.5.3) (80.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning==2.5.3) (3.19.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning==2.5.3) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning==2.5.3) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning==2.5.3) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning==2.5.3) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohan\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.57.0->pytorch-lightning==2.5.3) (0.4.6)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna>=3.5) (1.16.4)\n",
      "Requirement already satisfied: colorlog in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna>=3.5) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna>=3.5) (2.0.43)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.8) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.8) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.8) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.8) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.8) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.8) (3.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.3) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.3) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.3) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.3) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.3) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.3) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.3) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.3) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.3) (3.10)\n",
      "Requirement already satisfied: Mako in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.5) (1.3.10)\n",
      "Requirement already satisfied: tomli in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.5) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohan\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=2.2) (1.17.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast==3.0.2) (8.2.1)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast==3.0.2) (4.25.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast==3.0.2) (1.1.1)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast==3.0.2) (6.32.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast==3.0.2) (2.32.5)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray[tune]>=2.2.0->neuralforecast==3.0.2) (2.6.4)\n",
      "Requirement already satisfied: pyarrow>=9.0.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray[tune]>=2.2.0->neuralforecast==3.0.2) (21.0.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna>=3.5) (3.2.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=2.1.0->pytorch-lightning==2.5.3) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast==3.0.2) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast==3.0.2) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast==3.0.2) (0.27.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast==3.0.2) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast==3.0.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast==3.0.2) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "{'torch': '2.6.0+cu126', 'torch_cuda': '12.6', 'cuda_available': True, 'gpu': 'NVIDIA GeForce RTX 4060 Ti', 'has_LRScheduler': True, 'lightning': '2.5.3', 'neuralforecast': '3.0.2', 'pytorch_forecasting': '1.4.0'}\n"
     ]
    }
   ],
   "source": [
    "# Setup for Windows NVIDIA\n",
    "\n",
    "import sys, platform\n",
    "print(\"Kernel interpreter:\", sys.executable)\n",
    "print(\"Python version   :\", platform.python_version())\n",
    "\n",
    "%pip install -U pip setuptools wheel\n",
    "#ARIMA/SARIMAX\n",
    "%pip install -U statsmodels\n",
    "\n",
    "#  Torch 2.6.0 + CUDA 12.6  (pairs with torchvision 0.21.0)\n",
    "%pip install torch==2.6.0 torchvision==0.21.0 --index-url https://download.pytorch.org/whl/cu126\n",
    "\n",
    "# Rest of the stack \n",
    "%pip install \"pytorch-lightning==2.5.3\" \"pytorch-forecasting==1.4.0\" \"neuralforecast==3.0.2\" \\\n",
    "             \"optuna>=3.5\" \"pandas>=2.2\" \"numpy>=1.26\" \"scikit-learn>=1.4\" \"matplotlib>=3.8\" \"seaborn>=0.13\"\n",
    "\n",
    "# --- sanity check (catches wrong kernel / CPU torch) \n",
    "import importlib, torch, pytorch_lightning as pl, torch.optim.lr_scheduler as lrs\n",
    "nf = importlib.import_module(\"neuralforecast\")\n",
    "pf = importlib.import_module(\"pytorch_forecasting\")\n",
    "\n",
    "print({\n",
    "    \"torch\": torch.__version__,\n",
    "    \"torch_cuda\": getattr(torch.version, \"cuda\", None),\n",
    "    \"cuda_available\": torch.cuda.is_available(),\n",
    "    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n",
    "    \"has_LRScheduler\": hasattr(lrs, \"LRScheduler\"),\n",
    "    \"lightning\": pl.__version__,\n",
    "    \"neuralforecast\": nf.__version__,\n",
    "    \"pytorch_forecasting\": pf.__version__,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcd5606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python': 'c:\\\\Users\\\\Rohan\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\python.exe', 'device': 'cuda', 'torch': '2.6.0+cu126', 'lightning': '2.5.3', 'neuralforecast': '3.0.2', 'pytorch_forecasting': '1.4.0'}\n"
     ]
    }
   ],
   "source": [
    "# Imports, config, reproducibility — Torch 2.x / Lightning 2.x / NF 3.x\n",
    "\n",
    "import os, json, math, time, warnings, random, sys\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# NeuralForecast (Informer)\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import Informer as NFInformer\n",
    "from neuralforecast.losses.pytorch import MSE\n",
    "\n",
    "# PyTorch-Forecasting (TFT baseline)\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# Reproducibility & device setup \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pl.seed_everything(42, workers=True)\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "DEVICE = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "RESULTS_DIR = Path(\"results\"); RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    RAW_FILE: str = \"pollution_2000_2023.csv\" \n",
    "    INPUT_WINDOW: int = 60\n",
    "    PRED_WINDOW: int = 3\n",
    "    TRAIN_END: str = \"2016-12-31\"\n",
    "    VAL_END: str   = \"2020-12-31\"\n",
    "    # Informer hyperparams\n",
    "    HIDDEN_SIZE: int = 128\n",
    "    N_HEAD: int = 4\n",
    "    FACTOR: int = 10\n",
    "    DROPOUT: float = 0.1\n",
    "    LR: float = 1e-3\n",
    "    MAX_STEPS: int = 5000\n",
    "    # Rolling evaluation\n",
    "    ROLL_STEP_DAYS: int = 7\n",
    "\n",
    "CFG = CFG()\n",
    "\n",
    "#catching kernal/env details in the event of mishap\n",
    "print({\n",
    "    \"python\": sys.executable,\n",
    "    \"device\": DEVICE,\n",
    "    \"torch\": torch.__version__,\n",
    "    \"lightning\": pl.__version__,\n",
    "    \"neuralforecast\": __import__(\"neuralforecast\").__version__,\n",
    "    \"pytorch_forecasting\": __import__(\"pytorch_forecasting\").__version__,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8569450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# metrics\n",
    "def rmse(a, b):\n",
    "    return float(np.sqrt(((np.asarray(a) - np.asarray(b)) ** 2).mean()))\n",
    "\n",
    "def smape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    denom = np.abs(y_true) + np.abs(y_pred) + eps\n",
    "    return float(100.0 * np.mean(np.abs(y_pred - y_true) / denom))\n",
    "\n",
    "# like units for reporting\n",
    "# In this Kaggle/EPA daily file: NO2 values are in ppb; O3/CO/SO2 typically in ppm.\n",
    "PPB_SCALE = {\"O3\": 1000.0, \"CO\": 1000.0, \"SO2\": 1000.0, \"NO2\": 1.0}\n",
    "\n",
    "def to_ppb(arr, pollutant):\n",
    "    s = PPB_SCALE[pollutant]\n",
    "    return np.asarray(arr) * s\n",
    "\n",
    "##column name and schema conversion\n",
    "def load_and_standardize(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the Kaggle 'U.S. Pollution Data 2000-2023' CSV and normalizes schema:\n",
    "      - lower_snake_case columns\n",
    "      - date column -> 'date' (datetime64)\n",
    "      - pollutants -> columns: 'o3', 'no2', 'so2', 'co'\n",
    "      - keep 'city', 'state'\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    df.columns = (\n",
    "        pd.Series(df.columns)\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
    "        .str.replace(r\"_+\", \"_\", regex=True)\n",
    "        .str.strip(\"_\")\n",
    "        .to_list()\n",
    "    )\n",
    "    # Date\n",
    "    date_candidates = [\"date\", \"date_local\", \"date_\"]\n",
    "    date_col = next((c for c in date_candidates if c in df.columns), None)\n",
    "    if date_col is None:\n",
    "        raise ValueError(\"No date column found. Expected one of: \" + \", \".join(date_candidates))\n",
    "    df[\"date\"] = pd.to_datetime(df[date_col])\n",
    "    # City/State\n",
    "    if \"city\" not in df.columns or \"state\" not in df.columns:\n",
    "        raise ValueError(\"Expected 'city' and 'state' columns.\")\n",
    "    # Pollutants: accept either *_mean or simple names\n",
    "    name_map = {\n",
    "        \"o3\": [\"o3_mean\", \"o3\", \"ozone\"],\n",
    "        \"no2\": [\"no2_mean\", \"no2\"],\n",
    "        \"so2\": [\"so2_mean\", \"so2\"],\n",
    "        \"co\": [\"co_mean\", \"co\"],\n",
    "    }\n",
    "    out = pd.DataFrame({\n",
    "        \"date\": df[\"date\"],\n",
    "        \"city\": df[\"city\"].astype(str),\n",
    "        \"state\": df[\"state\"].astype(str),\n",
    "    })\n",
    "    for key, cands in name_map.items():\n",
    "        col = next((c for c in cands if c in df.columns), None)\n",
    "        if col is None:\n",
    "            raise ValueError(f\"Expected column for {key}: one of {cands}\")\n",
    "        out[key] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    # drop dupes/na and sort\n",
    "    out = out.dropna(subset=[\"o3\", \"no2\", \"so2\", \"co\"]).sort_values([\"city\", \"state\", \"date\"]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "def make_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calendar features + simple lag(1) per pollutant.\"\"\"\n",
    "    out = df.copy()\n",
    "    out[\"month\"] = out[\"date\"].dt.month.astype(int)\n",
    "    out[\"dayofweek\"] = out[\"date\"].dt.dayofweek.astype(int)\n",
    "    out[\"isweekend\"] = out[\"dayofweek\"].isin([5, 6]).astype(int)\n",
    "    out[\"iswedthur\"] = out[\"dayofweek\"].isin([2, 3]).astype(int)\n",
    "\n",
    "    # lag(1) per pollutant by city/state\n",
    "    for p in [\"o3\", \"no2\", \"so2\", \"co\"]:\n",
    "        out[f\"{p}_lag1\"] = out.groupby([\"city\", \"state\"])[p].shift(1)\n",
    "\n",
    "    # average pollution for context (same units as native)\n",
    "    out[\"pollution_avg\"] = out[[\"o3\", \"no2\", \"so2\", \"co\"]].mean(axis=1)\n",
    "    out = out.dropna().reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "def to_long(df_feat: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Melt wide -> long: (city,state,date) × pollutant -> y; create unique_id and y_lag1 by series.\"\"\"\n",
    "    long = df_feat.melt(\n",
    "        id_vars=[\"date\", \"city\", \"state\", \"month\", \"dayofweek\", \"isweekend\", \"iswedthur\",\n",
    "                 \"o3_lag1\", \"no2_lag1\", \"so2_lag1\", \"co_lag1\", \"pollution_avg\"],\n",
    "        value_vars=[\"o3\", \"no2\", \"so2\", \"co\"],\n",
    "        var_name=\"pollutant\",\n",
    "        value_name=\"y\",\n",
    "    )\n",
    "    long[\"pollutant\"] = long[\"pollutant\"].str.upper()\n",
    "    long[\"unique_id\"] = (\n",
    "        long[\"city\"].str.replace(r\"[^A-Za-z0-9]+\", \"\", regex=True)\n",
    "        + \"_\" +\n",
    "        long[\"state\"].str.replace(r\"[^A-Za-z0-9]+\", \"\", regex=True)\n",
    "        + \"_\" +\n",
    "        long[\"pollutant\"].str.lower()\n",
    "    ).str.lower()\n",
    "    long = long.sort_values([\"unique_id\", \"date\"]).reset_index(drop=True)\n",
    "    # create a universal y_lag1 in the long frame (per unique series)\n",
    "    long[\"y_lag1\"] = long.groupby(\"unique_id\")[\"y\"].shift(1)\n",
    "    long = long.dropna(subset=[\"y\", \"y_lag1\"]).reset_index(drop=True)\n",
    "    return long\n",
    "\n",
    "def pick_subset_cities(df: pd.DataFrame, top_n=8, min_years=10) -> list:\n",
    "    \"\"\"\n",
    "    Pick a representative subset by city with longest coverage.\n",
    "    Returns a list of city names (case-sensitive as in data).\n",
    "    \"\"\"\n",
    "    city_counts = (df.groupby([\"city\"])[\"date\"].count().rename(\"n\").reset_index())\n",
    "    # bias toward cities with the longest span (min max year diff)\n",
    "    spans = df.groupby(\"city\")[\"date\"].agg([\"min\", \"max\"])\n",
    "    spans[\"years\"] = (spans[\"max\"] - spans[\"min\"]).dt.days / 365.25\n",
    "    merged = city_counts.merge(spans.reset_index(), on=\"city\")\n",
    "    merged = merged[merged[\"years\"] >= min_years].sort_values([\"n\", \"years\"], ascending=False)\n",
    "    chosen = merged[\"city\"].head(top_n).tolist()\n",
    "    return chosen\n",
    "\n",
    "def print_split_counts(long_df, train_end, val_end):\n",
    "    train_mask = long_df[\"date\"] <= train_end\n",
    "    val_mask   = (long_df[\"date\"] > train_end) & (long_df[\"date\"] <= val_end)\n",
    "    test_mask  = long_df[\"date\"] > val_end\n",
    "    print(\"=== Split row counts ===\")\n",
    "    print({\n",
    "        \"raw_rows\": len(long_df),\n",
    "        \"train_rows\": int(train_mask.sum()),\n",
    "        \"val_rows\": int(val_mask.sum()),\n",
    "        \"test_rows\": int(test_mask.sum())\n",
    "    })\n",
    "    uniq = lambda m: long_df.loc[m, \"unique_id\"].nunique()\n",
    "    print(\"=== Unique series per split ===\")\n",
    "    print({\n",
    "        \"train_unique_series\": uniq(train_mask),\n",
    "        \"val_unique_series\": uniq(val_mask),\n",
    "        \"test_unique_series\": uniq(test_mask),\n",
    "    })\n",
    "\n",
    "def anchors_between(start_ts, end_ts, step_days=14):\n",
    "    \"\"\"Yield anchor datetimes from start to end inclusive with given step.\"\"\"\n",
    "    cur = pd.Timestamp(start_ts)\n",
    "    end = pd.Timestamp(end_ts)\n",
    "    while cur <= end:\n",
    "        yield cur\n",
    "        cur += pd.Timedelta(days=step_days)\n",
    "\n",
    "# For consistent plotting fonts\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1942657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: pollution_2000_2023.csv | rows=665,414\n",
      "        date         city       state        o3        no2       so2        co\n",
      "0 2011-01-01  Albuquerque  New Mexico  0.032471   9.180952  0.054167  0.200000\n",
      "1 2011-01-02  Albuquerque  New Mexico  0.018824  11.504762  0.162500  0.275000\n",
      "2 2011-01-03  Albuquerque  New Mexico  0.008412  23.342857  0.720833  0.479167\n",
      "3 2011-01-04  Albuquerque  New Mexico  0.027471  23.245455  0.887500  0.604167\n",
      "4 2011-01-05  Albuquerque  New Mexico  0.033294  12.637500  0.445833  0.204167\n",
      "Feature columns added. Preview:\n",
      "             date        city       state        o3        no2       so2  \\\n",
      "29273  2007-02-03  Beltsville    Maryland  0.018824   9.434783  3.037500   \n",
      "522334 2019-11-19    Rubidoux  California  0.033353  26.479167  0.566667   \n",
      "372483 2012-05-19      Newark  New Jersey  0.028706  25.583333  2.983333   \n",
      "527499 2016-06-10     Rutland     Vermont  0.013417   1.873333  0.010000   \n",
      "571718 2021-12-10     Seattle  Washington  0.022765  10.531818  0.095833   \n",
      "\n",
      "              co  month  dayofweek  isweekend  iswedthur   o3_lag1   no2_lag1  \\\n",
      "29273   0.158333      2          5          1          0  0.007412  20.304348   \n",
      "522334  0.495833     11          1          0          0  0.033353  25.808333   \n",
      "372483  0.429167      5          5          1          0  0.018824  22.750000   \n",
      "527499  0.029412      6          4          0          0  0.028471   1.317391   \n",
      "571718  0.204167     12          4          0          0  0.018353  10.233333   \n",
      "\n",
      "        so2_lag1   co_lag1  pollution_avg  \n",
      "29273   6.479167  0.295833       3.162360  \n",
      "522334  0.566667  0.475000       6.893755  \n",
      "372483  1.450000  0.350000       7.256135  \n",
      "527499  0.027273  0.016667       0.481540  \n",
      "571718  0.077273  0.208333       2.713646  \n",
      "Chosen subset cities: ['Not in a city', 'Los Angeles', 'New York', 'Rubidoux', 'Phoenix', 'North Little Rock', 'Houston', 'Charlotte']\n",
      "Long rows: 615,496 | series=104\n",
      "                    unique_id       date         y\n",
      "0  charlotte_northcarolina_co 2000-04-02  0.500000\n",
      "1  charlotte_northcarolina_co 2000-04-03  0.500000\n",
      "2  charlotte_northcarolina_co 2000-04-04  0.500000\n",
      "3  charlotte_northcarolina_co 2000-04-05  0.533333\n",
      "4  charlotte_northcarolina_co 2000-04-06  0.500000\n"
     ]
    }
   ],
   "source": [
    "# load raw CSV, add features, choose subset cities, long format\n",
    "\n",
    "# load & feature engineering ----\n",
    "df_raw = load_and_standardize(CFG.RAW_FILE)\n",
    "print(f\"Loaded: {CFG.RAW_FILE} | rows={len(df_raw):,}\")\n",
    "print(df_raw.head())\n",
    "\n",
    "df_feat = make_features(df_raw)\n",
    "print(\"Feature columns added. Preview:\")\n",
    "print(df_feat.sample(5).head(10))\n",
    "\n",
    "# picking a small subset for demo (top N cities by coverage) ----\n",
    "TOP_N_CITIES = 8 #for this demo choosing 8 cities so it runs at a decent pace\n",
    "SUBSET_CITIES = pick_subset_cities(df_feat, top_n=TOP_N_CITIES, min_years=10)\n",
    "print(\"Chosen subset cities:\", SUBSET_CITIES)\n",
    "\n",
    "df_sub = df_feat[df_feat[\"city\"].isin(SUBSET_CITIES)].copy()\n",
    "\n",
    "# ---- Long format ----\n",
    "df_long = to_long(df_sub)\n",
    "print(f\"Long rows: {len(df_long):,} | series={df_long['unique_id'].nunique()}\")\n",
    "print(df_long[[\"unique_id\", \"date\", \"y\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0832660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Split row counts ===\n",
      "{'raw_rows': 615496, 'train_rows': 421744, 'val_rows': 120672, 'test_rows': 73080}\n",
      "=== Unique series per split ===\n",
      "{'train_unique_series': 104, 'val_unique_series': 60, 'test_unique_series': 52}\n",
      "Date ranges: 2000-01-02 → 2016-12-31 (train) | 2017-01-01 → 2020-12-31 (val) | 2021-01-01 → 2023-09-30 (test)\n"
     ]
    }
   ],
   "source": [
    "# chronological splits + sanity check stats\n",
    "\n",
    "TRAIN_END = pd.Timestamp(CFG.TRAIN_END)\n",
    "VAL_END   = pd.Timestamp(CFG.VAL_END)\n",
    "\n",
    "print_split_counts(df_long, TRAIN_END, VAL_END)\n",
    "\n",
    "train_mask = df_long[\"date\"] <= TRAIN_END\n",
    "val_mask  = (df_long[\"date\"] > TRAIN_END) & (df_long[\"date\"] <= VAL_END)\n",
    "test_mask = df_long[\"date\"] > VAL_END\n",
    "\n",
    "df_train = df_long[train_mask].copy()\n",
    "df_val = df_long[val_mask].copy()\n",
    "df_test = df_long[test_mask].copy()\n",
    "\n",
    "print(\"Date ranges:\",\n",
    "      df_train[\"date\"].min().date(), \"→\", df_train[\"date\"].max().date(), \"(train)\",\n",
    "      \"|\", df_val[\"date\"].min().date() if len(df_val) else None, \"→\", df_val[\"date\"].max().date() if len(df_val) else None, \"(val)\",\n",
    "      \"|\", df_test[\"date\"].min().date() if len(df_test) else None, \"→\", df_test[\"date\"].max().date() if len(df_test) else None, \"(test)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4772313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared evaluation helpers (join, per‑pollutant metrics, rolling eval)\n",
    "\n",
    "def per_pollutant_metrics(truth_df: pd.DataFrame, pred_df: pd.DataFrame, model_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    truth_df: columns ['unique_id','date','pollutant','y']\n",
    "    pred_df : columns ['unique_id','date','y_pred']\n",
    "    Returns a per-pollutant DataFrame with R2, MSE(ppb^2), SMAPE(%).\n",
    "    \"\"\"\n",
    "    merged = (truth_df.merge(pred_df, on=[\"unique_id\",\"date\"], how=\"inner\")).copy()\n",
    "    out_rows = []\n",
    "    for pol, g in merged.groupby(\"pollutant\"):\n",
    "        # Harmonize to ppb for error magnitudes\n",
    "        y_ppb     = to_ppb(g[\"y\"].values, pol)\n",
    "        yhat_ppb  = to_ppb(g[\"y_pred\"].values, pol)\n",
    "        out_rows.append({\n",
    "            \"model\": model_name,\n",
    "            \"pollutant\": pol,\n",
    "            \"R2\": float(r2_score(g[\"y\"].values, g[\"y_pred\"].values)),  # unit-invariant\n",
    "            \"MSE_ppb2\": float(np.mean((y_ppb - yhat_ppb)**2)),\n",
    "            \"SMAPE_%\": smape(y_ppb, yhat_ppb),\n",
    "            \"N\": int(len(g))\n",
    "        })\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "def rolling_eval(\n",
    "    predict_fn,            # callable(anchor_ts) -> DataFrame with ['unique_id','date','y_pred']\n",
    "    truth_full: pd.DataFrame,  # full long truth df (we will slice per-anchor)\n",
    "    start_ts: pd.Timestamp,\n",
    "    end_ts: pd.Timestamp,\n",
    "    step_days: int,\n",
    "    horizon: int,\n",
    "    model_name: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calls predict_fn(anchor) at each rolling anchor and aggregates per-pollutant metrics.\n",
    "    Returns a table: [anchor, pollutant, R2, MSE_ppb2, SMAPE_%, N]\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for a in anchors_between(start_ts, end_ts - pd.Timedelta(days=horizon-1), step_days=step_days):\n",
    "        # restrict truth to the H-day window after anchor\n",
    "        mask = (truth_full[\"date\"] > a) & (truth_full[\"date\"] <= a + pd.Timedelta(days=horizon))\n",
    "        truth = truth_full.loc[mask, [\"unique_id\",\"date\",\"pollutant\",\"y\"]].copy()\n",
    "        preds = predict_fn(a)\n",
    "        met = per_pollutant_metrics(truth, preds, model_name)\n",
    "        met.insert(0, \"anchor_date\", a.date().isoformat())\n",
    "        rows.append(met)\n",
    "    return pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=[\"anchor_date\",\"model\",\"pollutant\",\"R2\",\"MSE_ppb2\",\"SMAPE_%\",\"N\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97d8f6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Informer on subset cities …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss          | MSE           | 0      | train\n",
      "1 | padder_train  | ConstantPad1d | 0      | train\n",
      "2 | scaler        | TemporalNorm  | 0      | train\n",
      "3 | enc_embedding | DataEmbedding | 192    | train\n",
      "4 | dec_embedding | DataEmbedding | 192    | train\n",
      "5 | encoder       | TransEncoder  | 54.8 K | train\n",
      "6 | decoder       | TransDecoder  | 38.0 K | train\n",
      "--------------------------------------------------------\n",
      "93.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "93.2 K    Total params\n",
      "0.373     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 4/4 [00:00<00:00,  8.79it/s, v_num=615, train_loss_step=0.942, train_loss_epoch=0.984]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 4/4 [00:00<00:00,  8.69it/s, v_num=615, train_loss_step=0.942, train_loss_epoch=0.984]\n",
      "Informer trained in 99.40 s\n",
      "Informer: predicting first horizon …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 45.45it/s]\n",
      "Informer — immediate horizon metrics (subset, ppb units for errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>pollutant</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE_ppb2</th>\n",
       "      <th>SMAPE_%</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Informer</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.598111</td>\n",
       "      <td>15576.516867</td>\n",
       "      <td>12.844706</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Informer</td>\n",
       "      <td>NO2</td>\n",
       "      <td>0.664154</td>\n",
       "      <td>17.494324</td>\n",
       "      <td>19.423934</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Informer</td>\n",
       "      <td>O3</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>37.393420</td>\n",
       "      <td>11.747590</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Informer</td>\n",
       "      <td>SO2</td>\n",
       "      <td>0.713647</td>\n",
       "      <td>45072.394529</td>\n",
       "      <td>28.943695</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model pollutant        R2      MSE_ppb2    SMAPE_%   N\n",
       "0  Informer        CO  0.598111  15576.516867  12.844706  66\n",
       "1  Informer       NO2  0.664154     17.494324  19.423934  66\n",
       "2  Informer        O3  0.014894     37.393420  11.747590  66\n",
       "3  Informer       SO2  0.713647  45072.394529  28.943695  66"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informer rolling eval from 2021-01-01 to 2023-09-30 every 7 days …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 54.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 55.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 56.85it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 45.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 43.02it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.56it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 46.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 51.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.64it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 51.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 42.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 51.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 41.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 51.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 51.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 54.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 57.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 57.68it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 46.45it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 55.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.42it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 55.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 54.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 57.03it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.85it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 39.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.42it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 45.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 54.91it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 42.79it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 55.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 56.08it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 42.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.98it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.40it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 50.42it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 45.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 46.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 46.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 45.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 50.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 39.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 54.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 55.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 57.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 46.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 46.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.52it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 50.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 55.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.98it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 40.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 50.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 50.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.67it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 50.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 55.01it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 39.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 42.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 43.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 50.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 51.17it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.17it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 43.08it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 46.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.06it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 39.03it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 43.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 38.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.43it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.06it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 45.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 51.29it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.17it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 50.37it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.11it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 55.80it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 51.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 58.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 56.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.68it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 55.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 49.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 47.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 42.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 48.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 42.58it/s]\n",
      "Rolling eval done in 69.31 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE_ppb2</th>\n",
       "      <th>SMAPE_%</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pollutant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>0.191</td>\n",
       "      <td>13866.335</td>\n",
       "      <td>16.398</td>\n",
       "      <td>7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO2</th>\n",
       "      <td>-0.060</td>\n",
       "      <td>27.651</td>\n",
       "      <td>19.302</td>\n",
       "      <td>7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O3</th>\n",
       "      <td>-0.019</td>\n",
       "      <td>57.766</td>\n",
       "      <td>10.501</td>\n",
       "      <td>7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO2</th>\n",
       "      <td>0.474</td>\n",
       "      <td>43426.649</td>\n",
       "      <td>32.140</td>\n",
       "      <td>7755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              R2   MSE_ppb2  SMAPE_%     N\n",
       "pollutant                                 \n",
       "CO         0.191  13866.335   16.398  7755\n",
       "NO2       -0.060     27.651   19.302  7755\n",
       "O3        -0.019     57.766   10.501  7755\n",
       "SO2        0.474  43426.649   32.140  7755"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Informer — train on subset, immediate & rolling evaluation (subset cities)\n",
    "\n",
    "# Build NeuralForecast long format: ['unique_id','ds','y']\n",
    "df_nf = df_long.rename(columns={\"date\":\"ds\"})[[\"unique_id\",\"ds\",\"y\"]].copy()\n",
    "\n",
    "# Train/val cut\n",
    "df_train_val_nf = df_nf[df_nf[\"ds\"] <= VAL_END].copy()\n",
    "\n",
    "INF_H = CFG.PRED_WINDOW\n",
    "INF_L = CFG.INPUT_WINDOW\n",
    "INF_HIDDEN = 64   \n",
    "INF_FACTOR = 10\n",
    "INF_HEADS = 4\n",
    "INF_MAX_STEPS = 1000   #lowered for demo\n",
    "INF_LR = CFG.LR\n",
    "\n",
    "nf_informer = NFInformer(\n",
    "    h=INF_H,\n",
    "    input_size=INF_L,\n",
    "    hidden_size=INF_HIDDEN,\n",
    "    n_head=INF_HEADS,\n",
    "    factor=INF_FACTOR,\n",
    "    dropout=CFG.DROPOUT,\n",
    "    learning_rate=INF_LR,\n",
    "    loss=MSE(),\n",
    "    scaler_type=\"standard\",\n",
    "    max_steps=INF_MAX_STEPS,\n",
    "    val_check_steps=100,   # evaluate every N steps\n",
    ")\n",
    "\n",
    "nf = NeuralForecast(models=[nf_informer], freq=\"D\")\n",
    "print(\"Training Informer on subset cities …\")\n",
    "t0 = time.perf_counter()\n",
    "nf.fit(df=df_train_val_nf)\n",
    "t_train = time.perf_counter() - t0\n",
    "print(f\"Informer trained in {t_train:.2f} s\")\n",
    "\n",
    "# ---------- Immediate-horizon eval (first test window) ----------\n",
    "first_anchor = pd.Timestamp(VAL_END)  # anchor at 2020-12-31, predict 2021-01-01..03\n",
    "def informer_predict_at(anchor_ts: pd.Timestamp) -> pd.DataFrame:\n",
    "    # Pass observed until anchor to forecast next H days (H fixed in model init)\n",
    "    df_cut = df_nf[df_nf[\"ds\"] <= anchor_ts].copy()\n",
    "\n",
    "    preds = nf.predict(df=df_cut)  # wide df: ['unique_id','ds','<model-name>']\n",
    "    pred_col = [c for c in preds.columns if c not in (\"unique_id\", \"ds\")][0]\n",
    "\n",
    "    # Standardize to our evaluation schema\n",
    "    preds = preds.rename(columns={pred_col: \"y_pred\", \"ds\": \"date\"})\n",
    "    preds[\"date\"] = pd.to_datetime(preds[\"date\"])\n",
    "\n",
    "    return preds[[\"unique_id\", \"date\", \"y_pred\"]]\n",
    "\n",
    "print(\"Informer: predicting first horizon …\")\n",
    "t0 = time.perf_counter()\n",
    "preds_first = informer_predict_at(first_anchor)\n",
    "t_pred = time.perf_counter() - t0\n",
    "\n",
    "# Prepare truth for first horizon\n",
    "mask = (df_long[\"date\"] > first_anchor) & (df_long[\"date\"] <= first_anchor + pd.Timedelta(days=INF_H))\n",
    "truth_first = df_long.loc[mask, [\"unique_id\",\"date\",\"pollutant\",\"y\"]].copy()\n",
    "\n",
    "inf_first_tbl = per_pollutant_metrics(truth_first, preds_first, \"Informer\")\n",
    "print(\"Informer — immediate horizon metrics (subset, ppb units for errors)\")\n",
    "display(inf_first_tbl)\n",
    "\n",
    "roll_start = df_test[\"date\"].min()\n",
    "roll_end   = df_test[\"date\"].max()\n",
    "STEP = CFG.ROLL_STEP_DAYS \n",
    "\n",
    "print(f\"Informer rolling eval from {roll_start.date()} to {roll_end.date()} every {STEP} days …\")\n",
    "t0 = time.perf_counter()\n",
    "inf_roll_tbl = rolling_eval(informer_predict_at, df_long, roll_start, roll_end, STEP, INF_H, \"Informer\")\n",
    "t_roll = time.perf_counter() - t0\n",
    "print(f\"Rolling eval done in {t_roll:.2f} s\")\n",
    "display(inf_roll_tbl.groupby([\"pollutant\"]).agg({\"R2\":\"mean\",\"MSE_ppb2\":\"mean\",\"SMAPE_%\":\"mean\",\"N\":\"sum\"}).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7edf262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>pollutant</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE_ppb2</th>\n",
       "      <th>SMAPE_%</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Informer</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.598</td>\n",
       "      <td>15576.517</td>\n",
       "      <td>12.845</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Informer</td>\n",
       "      <td>NO2</td>\n",
       "      <td>0.664</td>\n",
       "      <td>17.494</td>\n",
       "      <td>19.424</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Informer</td>\n",
       "      <td>O3</td>\n",
       "      <td>0.015</td>\n",
       "      <td>37.393</td>\n",
       "      <td>11.748</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Informer</td>\n",
       "      <td>SO2</td>\n",
       "      <td>0.714</td>\n",
       "      <td>45072.395</td>\n",
       "      <td>28.944</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model pollutant     R2   MSE_ppb2  SMAPE_%   N\n",
       "0  Informer        CO  0.598  15576.517   12.845  66\n",
       "1  Informer       NO2  0.664     17.494   19.424  66\n",
       "2  Informer        O3  0.015     37.393   11.748  66\n",
       "3  Informer       SO2  0.714  45072.395   28.944  66"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Harmonize units for reporting \n",
    "PPB_SCALE = {\"O3\": 1000.0, \"CO\": 1000.0, \"SO2\": 1000.0, \"NO2\": 1.0}\n",
    "\n",
    "def _norm_cols(df, date_col=\"date\"):\n",
    "    df = df.copy()\n",
    "    if \"ds\" in df.columns and date_col not in df.columns:\n",
    "        df = df.rename(columns={\"ds\": date_col})\n",
    "    if date_col in df.columns:\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "    return df\n",
    "\n",
    "def per_pollutant_metrics(truth_df: pd.DataFrame, pred_df: pd.DataFrame, model_name: str) -> pd.DataFrame:\n",
    "    from sklearn.metrics import r2_score\n",
    "    truth_df = _norm_cols(truth_df, \"date\")\n",
    "    pred_df  = _norm_cols(pred_df, \"date\")\n",
    "    merged = truth_df.merge(pred_df, on=[\"unique_id\",\"date\"], how=\"inner\")\n",
    "    out = []\n",
    "    for pol, g in merged.groupby(\"pollutant\"):\n",
    "        y   = g[\"y\"].values\n",
    "        yhat  = g[\"y_pred\"].values\n",
    "        y_ppb = y    * PPB_SCALE[pol]\n",
    "        yhat_p = yhat * PPB_SCALE[pol]\n",
    "        mse_ppb2 = float(np.mean((y_ppb - yhat_p)**2))\n",
    "        smape  = float(100*np.mean(np.abs(yhat_p - y_ppb)/(np.abs(yhat_p)+np.abs(y_ppb)+1e-8)))\n",
    "        r2    = float(r2_score(y, yhat)) \n",
    "        out.append({\"model\": model_name, \"pollutant\": pol, \"R2\": r2, \"MSE_ppb2\": mse_ppb2, \"SMAPE_%\": smape, \"N\": len(g)})\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "# Normalize input frames and compute metrics\n",
    "preds_first = _norm_cols(preds_first, \"date\").rename(columns=lambda c: c)\n",
    "truth_first = _norm_cols(truth_first, \"date\").rename(columns=lambda c: c)\n",
    "\n",
    "inf_first_tbl = per_pollutant_metrics(truth_first, preds_first[[\"unique_id\",\"date\",\"y_pred\"]], \"Informer\")\n",
    "display(inf_first_tbl.round(3))\n",
    "\n",
    "# Bar chart of R^2 by pollutant\n",
    "plt.figure(figsize=(7,3.5))\n",
    "plt.bar(inf_first_tbl[\"pollutant\"], inf_first_tbl[\"R2\"])\n",
    "plt.title(\"Informer R^2 by pollutant (first test horizon)\")\n",
    "plt.ylim(-0.2, 1.0)\n",
    "plt.ylabel(\"R^2\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bar chart of SMAPE by pollutant\n",
    "plt.figure(figsize=(7,3.5))\n",
    "plt.bar(inf_first_tbl[\"pollutant\"], inf_first_tbl[\"SMAPE_%\"])\n",
    "plt.title(\"Informer SMAPE by pollutant (first test horizon)\")\n",
    "plt.ylabel(\"SMAPE (%)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bffc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
